{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite musi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this sound...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>A Book That Is Worth a Second Look: This book...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Best game ever: This games makes even amazing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Guitar in Absentia: With all due respect to a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Stiff and Smells like drying paint: You get w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Review of Pillow: This was a joke. I am sendi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Label\n",
       "0     Stuning even for the non-gamer: This sound tr...      1\n",
       "1     The best soundtrack ever to anything.: I'm re...      1\n",
       "2     Amazing!: This soundtrack is my favorite musi...      1\n",
       "3     Excellent Soundtrack: I truly like this sound...      1\n",
       "4     Remember, Pull Your Jaw Off The Floor After H...      1\n",
       "..                                                 ...    ...\n",
       "194   A Book That Is Worth a Second Look: This book...      1\n",
       "195   Best game ever: This games makes even amazing...      1\n",
       "196   Guitar in Absentia: With all due respect to a...      0\n",
       "197   Stiff and Smells like drying paint: You get w...      0\n",
       "198   Review of Pillow: This was a joke. I am sendi...      0\n",
       "\n",
       "[199 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import model_selection, naive_bayes,svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "reviews_df=pd.read_csv('Amazon_Reviews.csv')\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-e1567c18ea49>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Number']=range(1,160)\n"
     ]
    }
   ],
   "source": [
    "y=reviews_df['Label']\n",
    "reviews_df.drop(columns='Label',inplace=True)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(reviews_df,y,test_size=0.2,random_state=42)\n",
    "\n",
    "X_train['Number']=range(1,160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-03b7d2b289ea>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Cleaned_text']=X_train['Review'].apply(preprocessing)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "183    hand track hear far complet though miss memor ...\n",
       "38     work mac clearli say line work mac os system d...\n",
       "24     like album thought would heard song two though...\n",
       "142    pattern detail sketch although excit purchas b...\n",
       "141    contemporari fairytal sure delight book take c...\n",
       "                             ...                        \n",
       "106    authent first encount yoruba say cd realli hel...\n",
       "14     aw beyond belief feel write keep other wast mo...\n",
       "92     omg soulwax own wow like amaz album ever everi...\n",
       "179    yet anoth unsubstanti case believ discrimin ce...\n",
       "102    ye got book expect much man wrong love book ma...\n",
       "Name: Cleaned_text, Length: 159, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "\n",
    "tokenizer =RegexpTokenizer(r'\\w+')\n",
    "lemmatizer=WordNetLemmatizer()      \n",
    "stemmer=PorterStemmer()\n",
    "\n",
    "def preprocessing(review):\n",
    "    \n",
    "    final_tokens=' '\n",
    "    \n",
    "    tokens=tokenizer.tokenize(review)\n",
    "    \n",
    "    pure_tokens=[token.lower() for token in tokens if token.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    stemmed_tokens=[stemmer.stem(pure_token) for pure_token in pure_tokens]\n",
    "    \n",
    "    final_tokens=final_tokens.join(stemmed_tokens)\n",
    "    \n",
    "    return final_tokens\n",
    "    \n",
    "X_train['Cleaned_text']=X_train['Review'].apply(preprocessing)\n",
    "X_train['Cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-6283c0f1445b>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Cleaned_text']=X_test['Review'].apply(preprocessing)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer=TfidfVectorizer(stop_words='english',use_idf=True)\n",
    "\n",
    "vectorizer.fit(X_train['Cleaned_text'])\n",
    "\n",
    "X_test['Cleaned_text']=X_test['Review'].apply(preprocessing)\n",
    "\n",
    "X_train_TfIdf= vectorizer.transform(X_train['Cleaned_text'])\n",
    "\n",
    "X_test_tfIdf=vectorizer.transform(X_test['Cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-3fb464a61c57>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Cleaned_text']=X_test['Review'].apply(preprocessing)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8,  7],\n",
       "       [ 1, 24]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix,roc_curve,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clf= MultinomialNB().fit(X_train_TfIdf.toarray(),y_train)\n",
    "\n",
    "X_test['Cleaned_text']=X_test['Review'].apply(preprocessing)\n",
    "\n",
    "y_pred=clf.predict(X_test_tfIdf.toarray())\n",
    "\n",
    "confusion_matrix(y_test,y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba_pred=clf.predict_proba(X_test_tfIdf.toarray())[::,1]\n",
    "\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_proba_pred)\n",
    "\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
